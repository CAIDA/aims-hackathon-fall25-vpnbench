{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 20250613 shape: (20118676, 7)\n",
      "DataFrame 20250923 shape: (20394284, 7)\n",
      "      network  hosting  proxy    tor  relay    vpn service\n",
      "0     1.0.0.0     True  False  False  False  False     NaN\n",
      "1     1.0.0.1     True  False  False  False   True     NaN\n",
      "2     1.0.0.2     True  False  False  False   True     NaN\n",
      "3     1.0.0.3     True  False  False  False  False     NaN\n",
      "4  1.0.0.4/30     True  False  False  False  False     NaN\n",
      "      network  hosting  proxy    tor  relay    vpn service\n",
      "0     1.0.0.0     True  False  False  False  False     NaN\n",
      "1     1.0.0.1     True  False  False  False   True     NaN\n",
      "2     1.0.0.2     True  False  False  False   True     NaN\n",
      "3     1.0.0.3     True  False  False  False  False     NaN\n",
      "4  1.0.0.4/30     True  False  False  False  False     NaN\n"
     ]
    }
   ],
   "source": [
    "csv_files = [file for file in os.listdir('data') if file.endswith('.csv')]\n",
    "\n",
    "df_20250613 = pd.read_csv(os.path.join('data', 'ipinfo_privacy.20250613.csv'))\n",
    "df_20250923 = pd.read_csv(os.path.join('data', 'ipinfo_privacy.20250923.csv'))\n",
    "\n",
    "print(\"DataFrame 20250613 shape:\", df_20250613.shape)\n",
    "print(\"DataFrame 20250923 shape:\", df_20250923.shape)\n",
    "\n",
    "print(df_20250613.head())\n",
    "print(df_20250923.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20118676 entries, 0 to 20118675\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   network  object\n",
      " 1   hosting  bool  \n",
      " 2   proxy    bool  \n",
      " 3   tor      bool  \n",
      " 4   relay    bool  \n",
      " 5   vpn      bool  \n",
      " 6   service  object\n",
      "dtypes: bool(5), object(2)\n",
      "memory usage: 402.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20394284 entries, 0 to 20394283\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   network  object\n",
      " 1   hosting  bool  \n",
      " 2   proxy    bool  \n",
      " 3   tor      bool  \n",
      " 4   relay    bool  \n",
      " 5   vpn      bool  \n",
      " 6   service  object\n",
      "dtypes: bool(5), object(2)\n",
      "memory usage: 408.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_20250613.info()\n",
    "df_20250923.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250613:\n",
      "-- Count: 8692856\n",
      "-- Proportion: 0.43207893004489956\n",
      "20250923:\n",
      "-- Count: 8655345\n",
      "-- Proportion: 0.424400533012093\n"
     ]
    }
   ],
   "source": [
    "def subnet_count(df):\n",
    "    return df['network'].str.contains('/').sum()\n",
    "\n",
    "subnet_count_20250613 = subnet_count(df_20250613)\n",
    "print(\"20250613:\")\n",
    "print(f\"-- Count: {subnet_count_20250613}\")\n",
    "print(f\"-- Proportion: {subnet_count_20250613 / len(df_20250613)}\")\n",
    "\n",
    "subnet_count_20250923 = subnet_count(df_20250923)\n",
    "print(\"20250923:\")\n",
    "print(f\"-- Count: {subnet_count_20250923}\")\n",
    "print(f\"-- Proportion: {subnet_count_20250923 / len(df_20250923)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed DataFrame 20250613 shape: (20118676, 7)\n",
      "Indexed DataFrame 20250923 shape: (20394284, 7)\n"
     ]
    }
   ],
   "source": [
    "# --- Optimization: Set 'network' as the index ---\n",
    "# This is the most crucial step for performance. Index-based operations\n",
    "# are significantly faster than column-based merges on large datasets.\n",
    "df_20250613_indexed = df_20250613.set_index('network')\n",
    "df_20250923_indexed = df_20250923.set_index('network')\n",
    "\n",
    "print(f\"Indexed DataFrame 20250613 shape: {df_20250613_indexed.shape}\")\n",
    "print(f\"Indexed DataFrame 20250923 shape: {df_20250923_indexed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPLITTING DATASETS BY IP VERSION ===\n",
      "Classifying IP versions for 2025-06-13 dataset...\n",
      "Classifying IP versions for 2025-09-23 dataset...\n",
      "\n",
      "2025-06-13 IP Version Distribution:\n",
      "ip_version\n",
      "4    16450714\n",
      "6     3667962\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2025-09-23 IP Version Distribution:\n",
      "ip_version\n",
      "4    16899121\n",
      "6     3495163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== CREATING SEPARATE IPV4 AND IPV6 DATASETS ===\n",
      "Normalizing IPv6 networks to /64 prefixes...\n",
      "IPv4 datasets (original networks):\n",
      "- 2025-06-13: 16,450,714 networks\n",
      "- 2025-09-23: 16,899,121 networks\n",
      "\n",
      "IPv6 datasets (before /64 normalization):\n",
      "- 2025-06-13: 3,667,962 networks\n",
      "- 2025-09-23: 3,495,163 networks\n",
      "\n",
      "Aggregating IPv6 data by /64 prefixes...\n",
      "IPv6 datasets (after /64 aggregation):\n",
      "- 2025-06-13: 226,166 /64 prefixes\n",
      "- 2025-09-23: 253,807 /64 prefixes\n",
      "\n",
      "Indexed datasets created successfully!\n",
      "IPv4: Using full IP addresses/networks\n",
      "IPv6: Using /64 prefixes with aggregated service classifications\n"
     ]
    }
   ],
   "source": [
    "# --- Split datasets by IP version (IPv4 vs IPv6) ---\n",
    "print(\"=== SPLITTING DATASETS BY IP VERSION ===\")\n",
    "\n",
    "def classify_ip_version(network_str):\n",
    "    \"\"\"Classify network as IPv4 or IPv6\"\"\"\n",
    "    try:\n",
    "        # Parse the network (handles both individual IPs and CIDR notation)\n",
    "        network = ipaddress.ip_network(network_str, strict=False)\n",
    "        return 4 if network.version == 4 else 6\n",
    "    except (ipaddress.AddressValueError, ValueError):\n",
    "        # If parsing fails, try to infer from format\n",
    "        if ':' in network_str:\n",
    "            return 6  # Likely IPv6\n",
    "        elif '.' in network_str:\n",
    "            return 4  # Likely IPv4\n",
    "        else:\n",
    "            return None  # Unknown\n",
    "\n",
    "def normalize_ipv6_to_64(network_str):\n",
    "    \"\"\"Normalize IPv6 addresses/networks to /64 prefixes\"\"\"\n",
    "    try:\n",
    "        # Parse as network first\n",
    "        network = ipaddress.ip_network(network_str, strict=False)\n",
    "        if network.version == 6:\n",
    "            # Get the /64 prefix (top 64 bits)\n",
    "            prefix_64 = network.supernet(new_prefix=64)\n",
    "            return str(prefix_64)\n",
    "        else:\n",
    "            return network_str  # Return as-is for IPv4\n",
    "    except (ipaddress.AddressValueError, ValueError):\n",
    "        return network_str  # Return as-is if parsing fails\n",
    "\n",
    "print(\"Classifying IP versions for 2025-06-13 dataset...\")\n",
    "df_20250613['ip_version'] = df_20250613['network'].apply(classify_ip_version)\n",
    "\n",
    "print(\"Classifying IP versions for 2025-09-23 dataset...\")\n",
    "df_20250923['ip_version'] = df_20250923['network'].apply(classify_ip_version)\n",
    "\n",
    "# Show version distribution\n",
    "print(f\"\\n2025-06-13 IP Version Distribution:\")\n",
    "print(df_20250613['ip_version'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\n2025-09-23 IP Version Distribution:\")\n",
    "print(df_20250923['ip_version'].value_counts().sort_index())\n",
    "\n",
    "# Split datasets by IP version\n",
    "print(f\"\\n=== CREATING SEPARATE IPV4 AND IPV6 DATASETS ===\")\n",
    "\n",
    "# IPv4 datasets - keep original networks\n",
    "df_20250613_ipv4 = df_20250613[df_20250613['ip_version'] == 4].copy()\n",
    "df_20250923_ipv4 = df_20250923[df_20250923['ip_version'] == 4].copy()\n",
    "\n",
    "# IPv6 datasets - normalize to /64 prefixes\n",
    "df_20250613_ipv6 = df_20250613[df_20250613['ip_version'] == 6].copy()\n",
    "df_20250923_ipv6 = df_20250923[df_20250923['ip_version'] == 6].copy()\n",
    "\n",
    "print(\"Normalizing IPv6 networks to /64 prefixes...\")\n",
    "df_20250613_ipv6['network_normalized'] = df_20250613_ipv6['network'].apply(normalize_ipv6_to_64)\n",
    "df_20250923_ipv6['network_normalized'] = df_20250923_ipv6['network'].apply(normalize_ipv6_to_64)\n",
    "\n",
    "print(f\"IPv4 datasets (original networks):\")\n",
    "print(f\"- 2025-06-13: {len(df_20250613_ipv4):,} networks\")\n",
    "print(f\"- 2025-09-23: {len(df_20250923_ipv4):,} networks\")\n",
    "\n",
    "print(f\"\\nIPv6 datasets (before /64 normalization):\")\n",
    "print(f\"- 2025-06-13: {len(df_20250613_ipv6):,} networks\") \n",
    "print(f\"- 2025-09-23: {len(df_20250923_ipv6):,} networks\")\n",
    "\n",
    "# Aggregate IPv6 data by /64 prefixes\n",
    "print(f\"\\nAggregating IPv6 data by /64 prefixes...\")\n",
    "\n",
    "def aggregate_ipv6_by_prefix(df):\n",
    "    \"\"\"Aggregate IPv6 data by /64 prefixes using logical OR for boolean columns\"\"\"\n",
    "    # Group by normalized network and aggregate\n",
    "    bool_cols = ['hosting', 'proxy', 'tor', 'relay', 'vpn']\n",
    "    agg_dict = {col: 'max' for col in bool_cols}  # max is equivalent to logical OR for booleans\n",
    "    agg_dict['service'] = 'first'  # Take first service value\n",
    "    agg_dict['ip_version'] = 'first'  # Keep IP version\n",
    "    \n",
    "    aggregated = df.groupby('network_normalized').agg(agg_dict).reset_index()\n",
    "    aggregated.rename(columns={'network_normalized': 'network'}, inplace=True)\n",
    "    return aggregated\n",
    "\n",
    "df_20250613_ipv6_agg = aggregate_ipv6_by_prefix(df_20250613_ipv6)\n",
    "df_20250923_ipv6_agg = aggregate_ipv6_by_prefix(df_20250923_ipv6)\n",
    "\n",
    "print(f\"IPv6 datasets (after /64 aggregation):\")\n",
    "print(f\"- 2025-06-13: {len(df_20250613_ipv6_agg):,} /64 prefixes\") \n",
    "print(f\"- 2025-09-23: {len(df_20250923_ipv6_agg):,} /64 prefixes\")\n",
    "\n",
    "# Set network as index for each split dataset\n",
    "df_20250613_ipv4_indexed = df_20250613_ipv4.set_index('network')\n",
    "df_20250923_ipv4_indexed = df_20250923_ipv4.set_index('network')\n",
    "df_20250613_ipv6_indexed = df_20250613_ipv6_agg.set_index('network')\n",
    "df_20250923_ipv6_indexed = df_20250923_ipv6_agg.set_index('network')\n",
    "\n",
    "print(f\"\\nIndexed datasets created successfully!\")\n",
    "print(f\"IPv4: Using full IP addresses/networks\")\n",
    "print(f\"IPv6: Using /64 prefixes with aggregated service classifications\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NETWORK ALIGNMENT CHECK - IPv4 vs IPv6 ===\n",
      "\n",
      "--- IPv4 Network Alignment ---\n",
      "Unique IPv4 networks in 2025-06-13: 16,450,714\n",
      "Unique IPv4 networks in 2025-09-23: 16,899,121\n",
      "\n",
      "IPv4 Network Alignment:\n",
      "- Networks only in old dataset: 7,773,757\n",
      "- Networks only in new dataset: 8,222,164\n",
      "- Common networks: 8,676,957\n",
      "\n",
      "Sample IPv4 missing in new: ['111.252.228.106', '109.170.146.171', '113.2.134.115', '115.235.79.82', '221.203.149.104']\n",
      "Sample IPv4 missing in old: ['189.46.14.245', '119.200.97.165', '50.151.4.10', '121.61.48.24', '13.58.14.88/30']\n",
      "\n",
      "--- IPv6 Network Alignment ---\n",
      "Unique IPv6 networks in 2025-06-13: 226,166\n",
      "Unique IPv6 networks in 2025-09-23: 253,807\n",
      "\n",
      "IPv6 Network Alignment:\n",
      "- Networks only in old dataset: 21,565\n",
      "- Networks only in new dataset: 49,206\n",
      "- Common networks: 204,601\n",
      "\n",
      "Sample IPv6 missing in new: ['2a01:4f8:10a:c00::/56', '2401:1770::/28', '2001:67c:9e0::/48', '2a00:1630:2:1e00::/55', '2a05:dfc6:9300::/40']\n",
      "Sample IPv6 missing in old: ['2a01:7a00:13:1000::/52', '2606:40:21e4:a000::/54', '2a03:5840:1618::/45', '2a0b:f4c2:2:1::/64', '2406:840:e210::/44']\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total common IPv4 networks: 8,676,957\n",
      "Total common IPv6 networks: 204,601\n",
      "Total common networks: 8,881,558\n",
      "IPv4 aligned datasets shape: (8676957, 7)\n",
      "IPv6 aligned datasets shape: (204601, 7)\n"
     ]
    }
   ],
   "source": [
    "# --- Network Alignment Check for IPv4 and IPv6 separately ---\n",
    "print(\"=== NETWORK ALIGNMENT CHECK - IPv4 vs IPv6 ===\")\n",
    "\n",
    "def analyze_network_alignment(df_old, df_new, ip_version):\n",
    "    \"\"\"Analyze network alignment for a specific IP version\"\"\"\n",
    "    print(f\"\\n--- {ip_version} Network Alignment ---\")\n",
    "    \n",
    "    networks_old = set(df_old.index)\n",
    "    networks_new = set(df_new.index)\n",
    "    \n",
    "    print(f\"Unique {ip_version} networks in 2025-06-13: {len(networks_old):,}\")\n",
    "    print(f\"Unique {ip_version} networks in 2025-09-23: {len(networks_new):,}\")\n",
    "    \n",
    "    # Check for differences\n",
    "    missing_in_new = networks_old - networks_new\n",
    "    missing_in_old = networks_new - networks_old\n",
    "    common_networks = networks_old & networks_new\n",
    "    \n",
    "    print(f\"\\n{ip_version} Network Alignment:\")\n",
    "    print(f\"- Networks only in old dataset: {len(missing_in_new):,}\")\n",
    "    print(f\"- Networks only in new dataset: {len(missing_in_old):,}\")\n",
    "    print(f\"- Common networks: {len(common_networks):,}\")\n",
    "    \n",
    "    if len(missing_in_new) > 0:\n",
    "        print(f\"\\nSample {ip_version} missing in new: {list(missing_in_new)[:5]}\")\n",
    "    if len(missing_in_old) > 0:\n",
    "        print(f\"Sample {ip_version} missing in old: {list(missing_in_old)[:5]}\")\n",
    "    \n",
    "    return common_networks\n",
    "\n",
    "# Analyze IPv4 networks\n",
    "ipv4_common_networks = analyze_network_alignment(df_20250613_ipv4_indexed, df_20250923_ipv4_indexed, \"IPv4\")\n",
    "\n",
    "# Analyze IPv6 networks  \n",
    "ipv6_common_networks = analyze_network_alignment(df_20250613_ipv6_indexed, df_20250923_ipv6_indexed, \"IPv6\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total common IPv4 networks: {len(ipv4_common_networks):,}\")\n",
    "print(f\"Total common IPv6 networks: {len(ipv6_common_networks):,}\")\n",
    "print(f\"Total common networks: {len(ipv4_common_networks) + len(ipv6_common_networks):,}\")\n",
    "\n",
    "# Create aligned dataframes for IPv4\n",
    "if len(ipv4_common_networks) > 0:\n",
    "    df_old_ipv4_aligned = df_20250613_ipv4_indexed.loc[list(ipv4_common_networks)].sort_index()\n",
    "    df_new_ipv4_aligned = df_20250923_ipv4_indexed.loc[list(ipv4_common_networks)].sort_index()\n",
    "    print(f\"IPv4 aligned datasets shape: {df_old_ipv4_aligned.shape}\")\n",
    "\n",
    "# Create aligned dataframes for IPv6\n",
    "if len(ipv6_common_networks) > 0:\n",
    "    df_old_ipv6_aligned = df_20250613_ipv6_indexed.loc[list(ipv6_common_networks)].sort_index()\n",
    "    df_new_ipv6_aligned = df_20250923_ipv6_indexed.loc[list(ipv6_common_networks)].sort_index()\n",
    "    print(f\"IPv6 aligned datasets shape: {df_old_ipv6_aligned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IPv4 SERVICE CLASSIFICATION CHURN ANALYSIS ===\n",
      "\n",
      "IPv4 HOSTING Classification Changes:\n",
      "- Total networks changed: 121,638\n",
      "- Gained hosting: 51,851\n",
      "- Lost hosting: 69,787\n",
      "- Churn rate: 1.4019%\n",
      "\n",
      "IPv4 PROXY Classification Changes:\n",
      "- Total networks changed: 1,136\n",
      "- Gained proxy: 371\n",
      "- Lost proxy: 765\n",
      "- Churn rate: 0.0131%\n",
      "\n",
      "IPv4 TOR Classification Changes:\n",
      "- Total networks changed: 39\n",
      "- Gained tor: 10\n",
      "- Lost tor: 29\n",
      "- Churn rate: 0.0004%\n",
      "\n",
      "IPv4 RELAY Classification Changes:\n",
      "- Total networks changed: 11\n",
      "- Gained relay: 11\n",
      "- Lost relay: 0\n",
      "- Churn rate: 0.0001%\n",
      "\n",
      "IPv4 VPN Classification Changes:\n",
      "- Total networks changed: 18,257\n",
      "- Gained vpn: 9,188\n",
      "- Lost vpn: 9,069\n",
      "- Churn rate: 0.2104%\n",
      "\n",
      "=== IPv4 OVERALL CLASSIFICATION CHURN ===\n",
      "- IPv4 networks with any service change: 140,058\n",
      "- IPv4 overall churn rate: 1.6141%\n",
      "- IPv4 stable networks (no changes): 8,536,899\n",
      "- IPv4 stability rate: 98.3859%\n"
     ]
    }
   ],
   "source": [
    "# --- IPv4 Service Classification Churn Analysis ---\n",
    "print(\"=== IPv4 SERVICE CLASSIFICATION CHURN ANALYSIS ===\")\n",
    "\n",
    "if len(ipv4_common_networks) > 0:\n",
    "    # Service columns to analyze\n",
    "    service_columns = ['hosting', 'proxy', 'tor', 'relay', 'vpn']\n",
    "    \n",
    "    # Track networks that changed for each service\n",
    "    ipv4_service_changes = {}\n",
    "    ipv4_total_changed_networks = set()\n",
    "    \n",
    "    for service in service_columns:\n",
    "        # Find networks where the service classification changed\n",
    "        old_values = df_old_ipv4_aligned[service]\n",
    "        new_values = df_new_ipv4_aligned[service]\n",
    "        \n",
    "        # Networks that changed (True->False or False->True)\n",
    "        changed_mask = old_values != new_values\n",
    "        changed_networks = df_old_ipv4_aligned[changed_mask].index.tolist()\n",
    "        \n",
    "        # Break down into specific change types\n",
    "        gained_service = df_old_ipv4_aligned[(old_values == False) & (new_values == True)].index.tolist()\n",
    "        lost_service = df_old_ipv4_aligned[(old_values == True) & (new_values == False)].index.tolist()\n",
    "        \n",
    "        ipv4_service_changes[service] = {\n",
    "            'total_changed': len(changed_networks),\n",
    "            'gained': len(gained_service),\n",
    "            'lost': len(lost_service),\n",
    "            'gained_networks': gained_service[:10],  # Sample\n",
    "            'lost_networks': lost_service[:10]       # Sample\n",
    "        }\n",
    "        \n",
    "        ipv4_total_changed_networks.update(changed_networks)\n",
    "        \n",
    "        print(f\"\\nIPv4 {service.upper()} Classification Changes:\")\n",
    "        print(f\"- Total networks changed: {len(changed_networks):,}\")\n",
    "        print(f\"- Gained {service}: {len(gained_service):,}\")\n",
    "        print(f\"- Lost {service}: {len(lost_service):,}\")\n",
    "        print(f\"- Churn rate: {len(changed_networks)/len(ipv4_common_networks)*100:.4f}%\")\n",
    "    \n",
    "    print(f\"\\n=== IPv4 OVERALL CLASSIFICATION CHURN ===\")\n",
    "    print(f\"- IPv4 networks with any service change: {len(ipv4_total_changed_networks):,}\")\n",
    "    print(f\"- IPv4 overall churn rate: {len(ipv4_total_changed_networks)/len(ipv4_common_networks)*100:.4f}%\")\n",
    "    print(f\"- IPv4 stable networks (no changes): {len(ipv4_common_networks) - len(ipv4_total_changed_networks):,}\")\n",
    "    print(f\"- IPv4 stability rate: {(len(ipv4_common_networks) - len(ipv4_total_changed_networks))/len(ipv4_common_networks)*100:.4f}%\")\n",
    "else:\n",
    "    print(\"No common IPv4 networks found for analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IPv6 SERVICE CLASSIFICATION CHURN ANALYSIS ===\n",
      "\n",
      "IPv6 HOSTING Classification Changes:\n",
      "- Total networks changed: 65\n",
      "- Gained hosting: 61\n",
      "- Lost hosting: 4\n",
      "- Churn rate: 0.0318%\n",
      "\n",
      "IPv6 PROXY Classification Changes:\n",
      "- Total networks changed: 8\n",
      "- Gained proxy: 2\n",
      "- Lost proxy: 6\n",
      "- Churn rate: 0.0039%\n",
      "\n",
      "IPv6 TOR Classification Changes:\n",
      "- Total networks changed: 5\n",
      "- Gained tor: 1\n",
      "- Lost tor: 4\n",
      "- Churn rate: 0.0024%\n",
      "\n",
      "IPv6 RELAY Classification Changes:\n",
      "- Total networks changed: 60\n",
      "- Gained relay: 60\n",
      "- Lost relay: 0\n",
      "- Churn rate: 0.0293%\n",
      "\n",
      "IPv6 VPN Classification Changes:\n",
      "- Total networks changed: 8\n",
      "- Gained vpn: 7\n",
      "- Lost vpn: 1\n",
      "- Churn rate: 0.0039%\n",
      "\n",
      "=== IPv6 OVERALL CLASSIFICATION CHURN ===\n",
      "- IPv6 networks with any service change: 144\n",
      "- IPv6 overall churn rate: 0.0704%\n",
      "- IPv6 stable networks (no changes): 204,457\n",
      "- IPv6 stability rate: 99.9296%\n"
     ]
    }
   ],
   "source": [
    "# --- IPv6 Service Classification Churn Analysis ---\n",
    "print(\"=== IPv6 SERVICE CLASSIFICATION CHURN ANALYSIS ===\")\n",
    "\n",
    "if len(ipv6_common_networks) > 0:\n",
    "    # Track networks that changed for each service\n",
    "    ipv6_service_changes = {}\n",
    "    ipv6_total_changed_networks = set()\n",
    "    \n",
    "    for service in service_columns:\n",
    "        # Find networks where the service classification changed\n",
    "        old_values = df_old_ipv6_aligned[service]\n",
    "        new_values = df_new_ipv6_aligned[service]\n",
    "        \n",
    "        # Networks that changed (True->False or False->True)\n",
    "        changed_mask = old_values != new_values\n",
    "        changed_networks = df_old_ipv6_aligned[changed_mask].index.tolist()\n",
    "        \n",
    "        # Break down into specific change types\n",
    "        gained_service = df_old_ipv6_aligned[(old_values == False) & (new_values == True)].index.tolist()\n",
    "        lost_service = df_old_ipv6_aligned[(old_values == True) & (new_values == False)].index.tolist()\n",
    "        \n",
    "        ipv6_service_changes[service] = {\n",
    "            'total_changed': len(changed_networks),\n",
    "            'gained': len(gained_service),\n",
    "            'lost': len(lost_service),\n",
    "            'gained_networks': gained_service[:10],  # Sample\n",
    "            'lost_networks': lost_service[:10]       # Sample\n",
    "        }\n",
    "        \n",
    "        ipv6_total_changed_networks.update(changed_networks)\n",
    "        \n",
    "        print(f\"\\nIPv6 {service.upper()} Classification Changes:\")\n",
    "        print(f\"- Total networks changed: {len(changed_networks):,}\")\n",
    "        print(f\"- Gained {service}: {len(gained_service):,}\")\n",
    "        print(f\"- Lost {service}: {len(lost_service):,}\")\n",
    "        print(f\"- Churn rate: {len(changed_networks)/len(ipv6_common_networks)*100:.4f}%\")\n",
    "    \n",
    "    print(f\"\\n=== IPv6 OVERALL CLASSIFICATION CHURN ===\")\n",
    "    print(f\"- IPv6 networks with any service change: {len(ipv6_total_changed_networks):,}\")\n",
    "    print(f\"- IPv6 overall churn rate: {len(ipv6_total_changed_networks)/len(ipv6_common_networks)*100:.4f}%\")\n",
    "    print(f\"- IPv6 stable networks (no changes): {len(ipv6_common_networks) - len(ipv6_total_changed_networks):,}\")\n",
    "    print(f\"- IPv6 stability rate: {(len(ipv6_common_networks) - len(ipv6_total_changed_networks))/len(ipv6_common_networks)*100:.4f}%\")\n",
    "else:\n",
    "    print(\"No common IPv6 networks found for analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
