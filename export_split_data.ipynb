{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Export Split Data by IP Version\n",
        "\n",
        "This notebook loads the original IPinfo privacy data, splits it by IP version (IPv4 vs IPv6), normalizes IPv6 to /64 prefixes, and exports the resulting 4 dataframes to CSV files for easier analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import ipaddress\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading original datasets...\n",
            "Original 2025-06-13 shape: (20118676, 7)\n",
            "Original 2025-09-23 shape: (20394284, 7)\n"
          ]
        }
      ],
      "source": [
        "# Load original datasets\n",
        "print(\"Loading original datasets...\")\n",
        "df_20250613 = pd.read_csv('data/ipinfo_privacy.20250613.csv')\n",
        "df_20250923 = pd.read_csv('data/ipinfo_privacy.20250923.csv')\n",
        "\n",
        "print(f\"Original 2025-06-13 shape: {df_20250613.shape}\")\n",
        "print(f\"Original 2025-09-23 shape: {df_20250923.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_ip_version(network_str):\n",
        "    \"\"\"Classify network as IPv4 or IPv6\"\"\"\n",
        "    try:\n",
        "        network = ipaddress.ip_network(network_str, strict=False)\n",
        "        return 4 if network.version == 4 else 6\n",
        "    except (ipaddress.AddressValueError, ValueError):\n",
        "        if ':' in network_str:\n",
        "            return 6  # Likely IPv6\n",
        "        elif '.' in network_str:\n",
        "            return 4  # Likely IPv4\n",
        "        else:\n",
        "            return None  # Unknown\n",
        "\n",
        "def normalize_ipv6_to_64(network_str):\n",
        "    \"\"\"Normalize IPv6 addresses/networks to /64 prefixes\"\"\"\n",
        "    try:\n",
        "        network = ipaddress.ip_network(network_str, strict=False)\n",
        "        if network.version == 6:\n",
        "            # Get the /64 prefix (top 64 bits)\n",
        "            prefix_64 = network.supernet(new_prefix=64)\n",
        "            return str(prefix_64)\n",
        "        else:\n",
        "            return network_str  # Return as-is for IPv4\n",
        "    except (ipaddress.AddressValueError, ValueError):\n",
        "        return network_str  # Return as-is if parsing fails\n",
        "\n",
        "def aggregate_ipv6_by_prefix(df):\n",
        "    \"\"\"Aggregate IPv6 data by /64 prefixes using logical OR for boolean columns\"\"\"\n",
        "    # Group by normalized network and aggregate\n",
        "    bool_cols = ['hosting', 'proxy', 'tor', 'relay', 'vpn']\n",
        "    agg_dict = {col: 'max' for col in bool_cols}  # max is equivalent to logical OR for booleans\n",
        "    agg_dict['service'] = 'first'  # Take first service value\n",
        "    agg_dict['ip_version'] = 'first'  # Keep IP version\n",
        "    \n",
        "    aggregated = df.groupby('network_normalized').agg(agg_dict).reset_index()\n",
        "    aggregated.rename(columns={'network_normalized': 'network'}, inplace=True)\n",
        "    return aggregated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying IP versions...\n",
            "2025-06-13 IP Version Distribution:\n",
            "ip_version\n",
            "4    16450714\n",
            "6     3667962\n",
            "Name: count, dtype: int64\n",
            "\n",
            "2025-09-23 IP Version Distribution:\n",
            "ip_version\n",
            "4    16899121\n",
            "6     3495163\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Classify IP versions\n",
        "print(\"Classifying IP versions...\")\n",
        "df_20250613['ip_version'] = df_20250613['network'].apply(classify_ip_version)\n",
        "df_20250923['ip_version'] = df_20250923['network'].apply(classify_ip_version)\n",
        "\n",
        "print(f\"2025-06-13 IP Version Distribution:\")\n",
        "print(df_20250613['ip_version'].value_counts().sort_index())\n",
        "\n",
        "print(f\"\\n2025-09-23 IP Version Distribution:\")\n",
        "print(df_20250923['ip_version'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Splitting datasets by IP version...\n",
            "IPv4 datasets:\n",
            "- 2025-06-13: 16,450,714 networks\n",
            "- 2025-09-23: 16,899,121 networks\n",
            "\n",
            "IPv6 datasets (before /64 normalization):\n",
            "- 2025-06-13: 3,667,962 networks\n",
            "- 2025-09-23: 3,495,163 networks\n"
          ]
        }
      ],
      "source": [
        "# Split by IP version\n",
        "print(\"\\nSplitting datasets by IP version...\")\n",
        "\n",
        "# IPv4 datasets - keep original networks\n",
        "df_20250613_ipv4 = df_20250613[df_20250613['ip_version'] == 4].copy()\n",
        "df_20250923_ipv4 = df_20250923[df_20250923['ip_version'] == 4].copy()\n",
        "\n",
        "# IPv6 datasets - normalize to /64 prefixes\n",
        "df_20250613_ipv6 = df_20250613[df_20250613['ip_version'] == 6].copy()\n",
        "df_20250923_ipv6 = df_20250923[df_20250923['ip_version'] == 6].copy()\n",
        "\n",
        "print(f\"IPv4 datasets:\")\n",
        "print(f\"- 2025-06-13: {len(df_20250613_ipv4):,} networks\")\n",
        "print(f\"- 2025-09-23: {len(df_20250923_ipv4):,} networks\")\n",
        "\n",
        "print(f\"\\nIPv6 datasets (before /64 normalization):\")\n",
        "print(f\"- 2025-06-13: {len(df_20250613_ipv6):,} networks\") \n",
        "print(f\"- 2025-09-23: {len(df_20250923_ipv6):,} networks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Normalizing IPv6 networks to /64 prefixes...\n",
            "Aggregating IPv6 data by /64 prefixes...\n",
            "IPv6 datasets (after /64 aggregation):\n",
            "- 2025-06-13: 226,166 /64 prefixes\n",
            "- 2025-09-23: 253,807 /64 prefixes\n"
          ]
        }
      ],
      "source": [
        "# Normalize IPv6 to /64 prefixes and aggregate\n",
        "print(\"\\nNormalizing IPv6 networks to /64 prefixes...\")\n",
        "df_20250613_ipv6['network_normalized'] = df_20250613_ipv6['network'].apply(normalize_ipv6_to_64)\n",
        "df_20250923_ipv6['network_normalized'] = df_20250923_ipv6['network'].apply(normalize_ipv6_to_64)\n",
        "\n",
        "print(\"Aggregating IPv6 data by /64 prefixes...\")\n",
        "df_20250613_ipv6_agg = aggregate_ipv6_by_prefix(df_20250613_ipv6)\n",
        "df_20250923_ipv6_agg = aggregate_ipv6_by_prefix(df_20250923_ipv6)\n",
        "\n",
        "print(f\"IPv6 datasets (after /64 aggregation):\")\n",
        "print(f\"- 2025-06-13: {len(df_20250613_ipv6_agg):,} /64 prefixes\") \n",
        "print(f\"- 2025-09-23: {len(df_20250923_ipv6_agg):,} /64 prefixes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created output directory: split_data\n"
          ]
        }
      ],
      "source": [
        "# Create output directory\n",
        "output_dir = Path('split_data')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Created output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting IPv4 datasets...\n",
            "Exported: split_data/ipv4_20250613.csv (16,450,714 rows)\n",
            "Exported: split_data/ipv4_20250923.csv (16,899,121 rows)\n"
          ]
        }
      ],
      "source": [
        "# Export IPv4 datasets\n",
        "print(\"Exporting IPv4 datasets...\")\n",
        "\n",
        "ipv4_20250613_path = output_dir / 'ipv4_20250613.csv'\n",
        "ipv4_20250923_path = output_dir / 'ipv4_20250923.csv'\n",
        "\n",
        "df_20250613_ipv4.to_csv(ipv4_20250613_path, index=False)\n",
        "df_20250923_ipv4.to_csv(ipv4_20250923_path, index=False)\n",
        "\n",
        "print(f\"Exported: {ipv4_20250613_path} ({len(df_20250613_ipv4):,} rows)\")\n",
        "print(f\"Exported: {ipv4_20250923_path} ({len(df_20250923_ipv4):,} rows)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exporting IPv6 datasets (aggregated to /64 prefixes)...\n",
            "Exported: split_data/ipv6_64_20250613.csv (226,166 rows)\n",
            "Exported: split_data/ipv6_64_20250923.csv (253,807 rows)\n"
          ]
        }
      ],
      "source": [
        "# Export IPv6 datasets (aggregated to /64 prefixes)\n",
        "print(\"\\nExporting IPv6 datasets (aggregated to /64 prefixes)...\")\n",
        "\n",
        "ipv6_20250613_path = output_dir / 'ipv6_64_20250613.csv'\n",
        "ipv6_20250923_path = output_dir / 'ipv6_64_20250923.csv'\n",
        "\n",
        "df_20250613_ipv6_agg.to_csv(ipv6_20250613_path, index=False)\n",
        "df_20250923_ipv6_agg.to_csv(ipv6_20250923_path, index=False)\n",
        "\n",
        "print(f\"Exported: {ipv6_20250613_path} ({len(df_20250613_ipv6_agg):,} rows)\")\n",
        "print(f\"Exported: {ipv6_20250923_path} ({len(df_20250923_ipv6_agg):,} rows)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== EXPORT COMPLETE ===\n",
            "All files exported to: /home/py/Documents/aims-hackathon-fall25-vpnbench/split_data\n",
            "\n",
            "Files created:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36628/1591309980.py:9: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_temp = pd.read_csv(file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ipv4_20250613.csv: 16,450,714 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36628/1591309980.py:9: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_temp = pd.read_csv(file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ipv4_20250923.csv: 16,899,121 rows\n",
            "  ipv6_64_20250613.csv: 226,166 rows\n",
            "  ipv6_64_20250923.csv: 253,807 rows\n",
            "\n",
            "Ready for churn analysis!\n"
          ]
        }
      ],
      "source": [
        "# Final summary\n",
        "print(\"\\n=== EXPORT COMPLETE ===\")\n",
        "print(f\"All files exported to: {output_dir.absolute()}\")\n",
        "\n",
        "print(\"\\nFiles created:\")\n",
        "for file_path in sorted(output_dir.glob('*')):\n",
        "    if file_path.is_file():\n",
        "        if file_path.suffix == '.csv':\n",
        "            df_temp = pd.read_csv(file_path)\n",
        "            print(f\"  {file_path.name}: {len(df_temp):,} rows\")\n",
        "        else:\n",
        "            print(f\"  {file_path.name}: {file_path.stat().st_size} bytes\")\n",
        "\n",
        "print(\"\\nReady for churn analysis!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
